<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Gabe Hege</title>
    <link>https://pghege.com/tags/machine-learning/index.xml</link>
    <description>Recent content in Machine Learning on Gabe Hege</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Learning from Crowds</title>
      <link>https://pghege.com/project/cocosci/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pghege.com/project/cocosci/</guid>
      <description>

&lt;p&gt;[&lt;a href=&#34;https://pghege.com/research/cocosci.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;

&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;VerbCorner is an online linguistics project which works to figure out what verbs mean using semantic structure and further understand how we communicate with one another. Figuring out what verbs mean is a large undertaking and requires many annotations to be made. VerbCorner takes the approach of presenting a short story to go along with a question at the end asking about various types of meaning. With the help of many people, the task of annotating verbs is a lot easier; but then we are left with the task of validating the annotations. To evaluate the quality of the annotations we apply an item- response model described in Hovyâ€™s paper entitled Learning Whom to Trust with MACE[1]. The system that learns in an unsupervised way to do two things. 1) Identify which annotators are trustworthy and 2) predict the correct labels. We implemented a basic version of the model they described using probabilistic programming language Venture. Then we had the model run this model on the crowd sourced annotations on the semantic structure of verbs generated by users on VerbCorner. We tested the model in different conditions in hopes of finding out more about our data. Further refinement of the model, including taking a look at the priors distribution across the answers will have to be reconsidered.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
